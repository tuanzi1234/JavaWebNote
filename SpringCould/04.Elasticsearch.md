### 一、Elasticsearch安装
1. 下载Elasticsearch
```bash
docker run -d \
  --name es \
  -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  -e "discovery.type=single-node" \
  -v es-data:/usr/share/elasticsearch/data \
  -v es-plugins:/usr/share/elasticsearch/plugins \
  --privileged \
  --network hm-net \
  -p 9200:9200 \
  -p 9300:9300 \
  elasticsearch:7.12.1
```
2. 安装kibana
```bash
docker run -d \
--name kibana \
-e ELASTICSEARCH_HOSTS=http://es:9200 \
--network=hm-net \
-p 5601:5601  \
kibana:7.12.1
```
### 二、倒排索引
elasticsearch采用倒排索引:
- 文档: 每条数据就是一个文档
- 词条: 文档按照语义分成的词语
![1759164177362](image/04.Elasticsearch/1759164177362.png)
![1759164223179](image/04.Elasticsearch/1759164223179.png)
### 三、IK分词器
IK分词器是中文分词器
1. 下载ik分词器: ` docker exec -it es ./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip`
2. Ik选择器允许我们配置拓展词典来增加自定义的词库:
```xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
<comment>IK Analyzer 扩展配置</comment>
<!-- 用户可以在这里配置自己的扩展字典 -->
<entry key="ext_dict">mydict.dic</entry>
<!-- 用户可以在这里配置远程扩展字典 -->
<entry key="remote_ext_dict">http://192.168.0.1:8080/ext_dict.dic</entry>
<!-- 用户可以在这里配置扩展停止词字典 -->
<entry key="ext_stopwords">stropwords.dic</entry>
<!-- 用户可以在这里配置远程扩展停止词字典 -->
<entry key="remote_ext_stopwords">http://192.168.0.1:8080/stropwords.dic</entry>
</properties>
```
### 四、基本概念
1. 索引: 相同类型的文档的集合
  ![1759171781396](image/04.Elasticsearch/1759171781396.png)
2. 映射: 索引中文档的字段约束信息，类似表的结构约束
3. 关于MySQL和Elasticsearch的对比
   ![1759174662447](image/04.Elasticsearch/1759174662447.png)
### 五、索引库操作
#### **1. Mapping映射属性**
mapping是对索引库中文档的约束，常见的mapping属性有:
1. type: 字段数据类型，常见的简单类型有:
   - 字符串: text(可分词的文本), keyword(精确值，如品牌、国家、IP地址)
   - 数值: long, integer, short, byte, double
   - 布尔: boolean
   - 时间: date
   - 对象: object
2. index: 是否索引: true, false(默认为true，若为false则不会参与搜索)
3. analyzer: 分词器，使用那种分词器
4. properties: 该字段的子字段
#### **2. 索引库的CRUD**
Elasticsearch提供的API都是Restful风格：
![1759222925425](image/04.Elasticsearch/1759222925425.png)
1. 创建索引库: 
```json
PUT /索引库名称
{  
  "mappings": {  
    "properties": {  
      "字段名称1": {  
        "type": "字段数据类型",
        "analyzer": "分词器名称",
        "index": "是否参与索引, true/false",
        "子字段": {  
          //......
        }
      },
      "字段名称2": {  
        //......
      }
    }
  }
}
```
2. 查询索引库:
   `GET /索引库名称`
3. 删除索引库:
   `DELETE /索引库名称`
4. 修改索引库:
索引库和mapping一旦创建无法修改，但可以添加新的字段:
```json
PUT /索引库名称/_mapping
{  
  "properties": {  
    "新字段名称": {
      "type": "字段数据类型",
    }
  }
}
```
#### **3. 文档CRUD**
1. 新增文档:
```json
POST /索引库名称/_doc/文档id
{ 
  "字段名称1": "字段值1",
  "字段名称2": "字段值2",
  "字段名称3": {
    "子字段名称1": "子字段值1",
    "子字段名称2": "子字段值2"
    //......
  }
}
```
1. 查询文档:
   `GET /索引库名称/_doc/文档id`
2. 删除文档:
   `DELETE /索引库名称/_doc/文档id`
3. 修改文档:
   方式1: 全量修改，删除旧文档，添加新文档
   ```json
   PUT /索引库名称/_doc/文档id
   { 
    "字段名称1": "字段值1",
    "字段名称2": "字段值2",
    // ......
   }
   ```
   方式2: 增量修改，只修改指定的字段
   ```json
   POST /索引库名称/_update/文档id
   {  
    "doc": {  
      "字段名称1": "字段值1",
    }
   }
   ```
4. 批量操作:
Elasticsearch提供了bulk接口，可以批量操作索引库和文档:
```json
POST /_bulk
{ "index": {"_index": "索引库名称", "_id": "文档id"} }
{ "字段名称1": "字段值1", "字段名称2": "字段值2"}
{ "index": {"_index": "索引库名称", "_id": "文档id"} }
{ "字段名称1": "字段值1", "字段名称2": "字段值2"}
{ "delete": {"_index": "索引库名称", "_id": "文档id"} }
{ "update": {"_id": "文档id", "_index": "索引库名称"} }
{ "doc": {"字段名称1": "字段值1"} }
```
#### **4. DSL查询**
1. 基于DSL的基本查询语法：
```json
GET /索引库名称/_search
{  
  "query": {  
    "查询类型": {  
      "查询条件": "条件值"  // 如match_all就是查询所有
    }
  }
}
```
2. 叶子查询
- 全文检索(full text): 利用分词器对用户的输入内容分词，然后去词条列表中匹配。
  例如: 
  `match_query`: 对用户输入的内容进行分词，然后去倒排索引库检索:
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "match": {  
        "字段名称": "用户输入内容"
      }
    }
  }
  ```
  `multi_match_query`: 与`match`一样，但是可以同时匹配多个字段。
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "multi_match": {  
        "fields": ["字段名称1", "字段名称2"],
      }
    }
  }
  ```
- 精确查询: 不对用户输入内容分词，直接精确匹配，一般是查找keyword、数值、日期、布尔等类型。
  例如：
  `ids`:
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "ids": {  
        "values": ["文档id1", "文档id2"]
      }
    }
  }
  ```
  `range`:
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "range": {  
        "字段名称": {
          "gte": "最小值", // 加上e是指包括最小值，若需要排除最小值，直接用gt，最大值同理
          "lte": "最大值"
        }
      }
    }
  }
  ```
  `term`:
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "term": {  
        "字段名称": {
          "value": "字段值"
        }
      }
    }
  }
  ```
- 地理查询: 用于搜索地理位置。
  例如: `geo_distance` `geo_bounding_box`
3. 复合查询
- 基于逻辑运算组合叶子查询，实现组合条件，例如
  `bool`查询:
  - `must`: 所有条件必须满足，类似于"与"；
  - `should`: 任意条件满足，类似于"或"，
  - `must_not`: 所有条件都不满足，类似于"非"
  - `filter`: 过滤条件，不参与算分
  以下列商品查询为例：
  ```json
  GET /索引库名称/_search
  {  
    "query": {  
      "bool": { 
        "must": [
          { "match": { "name": "手机" } },
        ],
        "should": [
          { "term": { "brand": { "value": "品牌1" } } },
          { "term": { "brand": { "value": "品牌2" } } }
        ],
        "must_not": [
          { "range": { "price": { "gte": "2500" } } }
        ],
        "filter": [
          { "range": { "price": { "lte": "2000"} } } 
        ]
      }
    }
  }
  ```
- 基于否中算法修改查询时的文档相关性算分，从而改变文档排名，例如:
  `function_score`
  `dis_max`
4. 排序和分页
可以排序的字段类型有: keyword、数值、地理坐标、日期。
```json
GET /索引库名称/_search
{  
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "字段名称": "排序方式" // asc/desc 升序/降序
    }
  ]
}
```
elasticsearch默认的分页大小为10，可以通过设置`from`和`size`来改变分页大小。
```json
GET /索引库名称/_search
{  
  "query": {
    "match_all": {}
  },
  "from": 0, // 从第几条开始 默认0
  "size": 10, // 分页大小, 期望获取的文档总数 默认10
  "sort": [
    { "字段名称": "排序方式" }
  ]
}
```
**深度分页问题:** 深度分页问题，即一次请求获取的文档数量过多，导致响应时间过长。
针对深度分页问题，给出两种解决方案:
- `search_after`: 原理是通过上一次的排序值开始，查询下一页的数据。
  优点: 没有查询上限，支持深度分页
  缺点: 不能随机翻页，只能逐页查询
  场景: 手机滚动查询
- `scroll`: 原理是将排序数据形成快照，保存在内存。
5. 高亮显示
```json
GET /索引库名称/_search
{  
  "query": { 
    "match": { 
      "字段名称": "用户输入内容"
    }
  },
  "highlight": {  
    "fields": {  // 指定高亮字段
      "字段名称": {
        "pre_tags": "<em>", // 高亮前置标签
        "post_tags": "</em>" // 高亮后置标签
      }
    }
  }
}
```
#### **5. 聚合**
1. 聚合可以实现对文档数据的统计、分析、运算等。常见的聚合类型:
- 桶(Bucket)聚合: 用来对文档做分组
  - TermAggregation: 按文档字段值进行分组
  - Date Histogram: 按日期进行分组，例如一周为一组
- 度量(Metric)聚合: 用以计算一些值，比如: 最大值、最小值、平均值等:
  - Avg: 平均值
  - Max: 最大值
  - Min: 最小值
  - Stats: 同时求最大值、最小值、平均值、和等
- 管道(pipeline)聚合: 以其他聚合的结果为基础做聚合
**注: 参与聚合的字段必须是Keyword、数值、日期、布尔类型的字段。**
2. DSL聚合
  如果要统计商品中共有哪些商品分类，其实就是以分类(category)字段对数据分组。category值一样的放在同一组中，属于Bucket聚合中的Term聚合。
  ```json
  GET /索引库名称/_search
  {  
    "query": { "match_all": {}}, // 可省略
    "size": 0, // 设置size为0, 结果中不包含文档，只包含聚合结果
    "aggs": {  // 定义聚合
      "category_agg": {  // 聚合名称
        "terms": {  // 聚合类型，按照分类聚合，属于terms聚合
          "field": "category", // 参与聚合的字段
          "size": 10 // 聚合结果中返回的分组数量
        }
      }
    }
  }
  ```
### 六、JavaRestClient
#### **1. 初始化**
1. 在使用到Elasticsearch的模块中引入RestHighLevelClient依赖:
```xml
<dependency>
  <groupId>org.elasticsearch.client</groupId>
  <artifactId>elasticsearch-rest-high-level-client</artifactId>
</dependency>
```
因为SpringBoot默认的ES版本为7.17.10，所以需要覆盖版本:
```xml
<properties>
    <maven.compiler.source>11</maven.compiler.source>
    <maven.compiler.target>11</maven.compiler.target>
    <elasticsearch.version>7.12.1</elasticsearch.version>
</properties>
```
1. 初始化:
```java
public class ElasticsearchTest { 
  private RestHighLevelClient client;
  @BeforeEach
  void setUp() { 
    client = new RestHighLevelClient(RestClient.builder(
         HttpHost.create("http://192.168.0.1:9200") // ES地址
    ));
  }
}

@AfterEach
void tearDown() throws IOException { 
  if (client != null) {
    client.close();
  }
}
```
#### **2. 商品Mapping映射**
索引的属性需要和数据库的字段一致，不参与搜索的字段需要设置`index: false`
```json
# 商品索引
PUT /hmall
{
  "mappings": {
    "properties": {
      "id":{
        "type": "keyword"
      },
      "name":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "price":{
        "type": "integer"
      },
      "image":{
        "type": "keyword",
        "index": false
      },
      "category":{
        "type": "keyword"
      },
      "brand":{
        "type": "keyword"
      },
      "sold":{
        "type": "integer"
      },
      "commentCount":{
        "type": "integer",
        "index": false
      },
      "isAD":{
        "type": "boolean"
      },
      "updateTime":{
        "type": "date"
      }
    }
  }
}
```
#### **3. 索引库操作**
1. 创建索引库：
```java
@Test
void createIndex() throws IOException { 
  // 1.创建Request对象, 对应Put /索引库名称
  CreateIndexRequest request = new CreateIndexRequest("hmall");
  // 2.请求参数，MAPPING_TEMPLATE是静态常量字符串，内容是JSON格式请求体，对应创建索引库的RestAPI
  request.source(MAPPING_TEMPLATE, XContentType.JSON);
  // 3.发送请求
  client.indices().create(request, RequestOptions.DEFAULT);
}
```
2. 删除索引库：
```java
@Test
void deleteIndex() throws IOException { 
  // 创建request对象
  DeleteIndexRequest request = new DeleteIndexRequest("hmall");
  // 发送请求
  client.indices().delete(request, RequestOptions.DEFAULT);
}
```
3. 查询索引库：
```java
@Test
void getIndex() throws IOException { 
  // 创建request对象
  GetIndexRequest request = new GetIndexRequest("hmall");
  // 发送请求
  client.indices().get(request, RequestOptions.DEFAULT);
}
```
#### **4. 文档操作**
1. 新增文档：
```java
@Test
void addDoc() throws IOException { 
  // 创建request对象
  IndexRequest request = new IndexRequest("hmall").id("1");
  // 准备Json文档
  request.source("{\"name\": \"Jack\"}", XContentType.JSON);
  // 发送请求
  client.index(request, RequestOptions.DEFAULT);
}
``` 
2. 删除文档：
```java
@Test
void deleteDoc() throws IOException { 
  // 创建request对象
  DeleteRequest request = new DeleteRequest("hmall", "1");
  // 发送请求
  client.delete(request, RequestOptions.DEFAULT);
}
```
3. 查询文档:
```java
@Test
void getDoc() throws IOException { 
  // 创建request对象
  GetRequest request = new GetRequest("hmall", "1");
  // 获取文档信息
  GetResponse response = client.get(request, RequestOptions.DEFAULT);
  // 解析响应结果
  String json = response.getSourceAsString();
  System.out.println(json);
}
```
4. 修改文档：
- 全量修改：与新增文档完全一致
- 局部更新, 只更新部分指定字段:
```java
@Test
void updateDoc() throws IOException { 
  // 创建request对象
  UpdateRequest request = new UpdateRequest("hmall", "1");
  // 准备参数
  request.doc(
    "name", "Tom"
    "age", 18
  );
  // 3.发送请求
  client.update(request, RequestOptions.DEFAULT);
}
```
#### **5. 批量操作**
```java
@Test
void batch() throws IOException { 
  // 创建Bulk请求
  BulkRequest request = new BulkRequest();
  // 添加批量提交的请求
  request.add(new IndexRequest("hmall").id("1").source("{\"name\": \"Jack\"}", XContentType.JSON));
  request.add(new IndexRequest("hmall").id("2").source("{\"name\": \"Tom\"}", XContentType.JSON));
  // 批量提交
  client.bulk(request, RequestOptions.DEFAULT);
}
```
#### **6. DSL查询**
数据搜索的java代码分为两部分:
1. 构建并发起请求
2. 解析响应结果
```java
@Test
void search() throws IOException { 
  // 准备request对象
  SearchRequest request = new SearchRequest("hmall");
  // 构建DSL, 相当于match_all
  request.source().query(QueryBuilders.matchAllQuery());
  // 发送请求
  SearchResponse response = client.search(request, RequestOptions.DEFAULT);
  // 解析响应结果......
}
```
#### **7. 构建查询条件**
- 全文检索的查询条件构造API如下:
```java
// 单字段查询
QueryBuilders.matchQuery("字段名", "查询条件");
// 多字段查询
QueryBuilders.multiMatchQuery("查询条件", "字段1", "字段2", "字段3");
```
- 精确查询的查询条件构造API如下:
```java
// 词条查询
QueryBuilders.termQuery("字段名", "查询条件");
// 范围查询
QueryBuilders.rangeQuery("字段名").gte(开始值).lte(结束值);
```
- 布尔查询的查询条件构造API如下：
```java
// 构造布尔查询对象
BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
// 添加must条件
boolQuery.must(QueryBuilders.matchQuery("字段1", "条件1"));
// 添加filter条件
boolQuery.filter(QueryBuilders.rangeQuery("字段2").gte(开始值).lte(结束值));
```
#### **8. 排序和分页**
与query类似，排序和分页也是基于request.source()构建:
```java
// 查询
SearchRequest request = new SearchRequest("hmall");
request.source().query(QueryBuilders.matchAllQuery());
// 分页（关于索引的计算：(页码 - 1) * 每页大小）
request.source().from(0).size(10);
// 排序 (以价格字段为例)
request.source().sort("price", SortOrder.DESC);
```
#### **9. 高亮**
高亮查询的java代码如下：
```java
request.source().highlighter(
  SearchSourceBuilder.highlight()
  .field("name")
  .preTags("<em>")
  .postTags("</em>")
);
```
获取高亮结果:
```java
// 承接上述处理结果步骤
// 1.得到_source
String source = hit.getSourceAsString();
// 2. 反序列化
Object obj = JSONUtil.toBean(source, Object.class);
// 3. 获取高亮结果
Map<String, HighlightField> highlightFields = hit.getHighlightFields();
if (!highlightFields.isEmpty() && highlightFields != null) { 
  HighlightField highlightField = highlightFields.get("name");
  if (highlightField != null) { 
    String name = highlightField.getFragments()[0].toString();
    obj.setName(name);
  }
}
```
#### **10. 聚合**
以品牌聚合为例:
```java
request.source().size(0);
request.source().aggregation(
  AggregationBuilders.terms("brand_agg").field("brand").size(20)
)
```
获取聚合结果：
```java
// 解析聚合结果
Aggregations aggregations = response.getAggregations();
// 根据名称来获取聚合结果
Terms brandAgg = aggregations.get("brand_agg");
// 获取桶
List<? extends Terms.Bucket> buckets = brandAgg.getBuckets();
// 遍历
buckets.forEach(bucket -> { 
  // 获取桶中的key，即品牌名称
  String key = bucket.getKeyAsString();
  System.out.println(key);
})
```
